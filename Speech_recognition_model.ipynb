{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ada24c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The output of this section is the CSV files with the data to be handle by the model\n",
    "CREATE_CSV_FILES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "43a559c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEECH_TRAIN_CSV_FILE = \"speach_recognition_train.csv\"\n",
    "SPEECH_TEST_CSV_FILE = \"speech_recognition_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "70c6a74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import zipfile as zf\n",
    "import csv\n",
    "import os\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "# import zipfile as zf\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c5d30268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWavFeatures(soundFilesFolder, csvFileName):\n",
    "    print(\"The features of the files in the folder \"+soundFilesFolder+\" will be saved to \"+csvFileName)\n",
    "    header = 'filename chroma_stft rmse spectral_centroid spectral_bandwidth rolloff zero_crossing_rate'\n",
    "#     for i in range(1, 61):\n",
    "#         header += f' mfcc{i}'\n",
    "    header += ' label'\n",
    "    header = header.split()\n",
    "#     print('CSV Header: ', header)\n",
    "    file = open(csvFileName, 'w', newline='')\n",
    "    #with file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(header)\n",
    "    for filename in os.listdir(soundFilesFolder):\n",
    "        if filename.endswith('.wav'):\n",
    "            number = f'{soundFilesFolder}/{filename}'\n",
    "            y, sr = librosa.load(number, mono=True, duration = 30)\n",
    "            # remove leading and trailing silence\n",
    "            y, index = librosa.effects.trim(y)\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            rmse = librosa.feature.rms(y=y)\n",
    "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "#             mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc = 60)\n",
    "            to_append = f'{filename} {np.mean(rmse)} {np.mean(chroma_stft)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "#             for e in mfcc:\n",
    "#                 to_append += f' {np.mean(e)}'\n",
    "            writer.writerow(to_append.split())\n",
    "    file.close()\n",
    "    print(\"End of extractWavFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f7d0cf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features of the files in the folder Audio_Data/Speech_Recognition_Train_Data_final will be saved to speach_recognition_train.csv\n",
      "End of extractWavFeatures\n",
      "The features of the files in the folder Audio_Data/Speach_test_data will be saved to speech_recognition_test.csv\n",
      "End of extractWavFeatures\n",
      "CSV files are created\n"
     ]
    }
   ],
   "source": [
    "if (CREATE_CSV_FILES == True):\n",
    "    extractWavFeatures(\"Audio_Data/Speech_Recognition_Train_Data_final\", SPEECH_TRAIN_CSV_FILE)\n",
    "    extractWavFeatures(\"Audio_Data/Speach_test_data\", SPEECH_TEST_CSV_FILE)\n",
    "    print(\"CSV files are created\")\n",
    "else:\n",
    "    print(\"CSV files creation is skipped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e334efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading a dataset and convert file name to corresbonding number\n",
    "def speech_preProcessData(csvFileName):\n",
    "#     header_name_list = ['filename', 'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate', 'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', 'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20', 'mfcc21', 'mfcc22', 'mfcc23', 'mfcc24', 'mfcc25', 'mfcc26', 'mfcc27', 'mfcc28', 'mfcc29', 'mfcc30', 'mfcc31', 'mfcc32', 'mfcc33', 'mfcc34', 'mfcc35', 'mfcc36', 'mfcc37', 'mfcc38', 'mfcc39', 'mfcc40', 'label']\n",
    "    print(csvFileName+ \" will be preprocessed\")\n",
    "    data =  pd.read_csv(csvFileName)\n",
    "#     data = pd.read_csv(csvFileName, skiprows=[1, 50]\n",
    "    # we have 2 sentances: \n",
    "    # 0: open the door\n",
    "    # 1: close the door\n",
    "    filenameArray = data['filename'] \n",
    "    speechTypeArray = []\n",
    "#     print(filenameArray)\n",
    "    for filename in filenameArray:\n",
    "        #print(speaker)\n",
    "        if \"open_the_door\" in filename:\n",
    "            speaker = 0\n",
    "        else: \n",
    "            speaker = 1\n",
    "#         print(speaker)\n",
    "        speechTypeArray.append(speaker)\n",
    "    data['number'] = speechTypeArray\n",
    "    #Dropping unnecessary columns\n",
    "    data = data.drop(['filename'],axis=1)\n",
    "    data = data.drop(['label'],axis=1)\n",
    "#     data = data.drop(['chroma_stft'],axis=1)\n",
    "#     data.shape\n",
    "#     print(\"Preprocessing is finished\")\n",
    "#     print(data[['filename', 'number']])\n",
    "#     print(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "7199b02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speach_recognition_train.csv will be preprocessed\n",
      "speech_recognition_test.csv will be preprocessed\n"
     ]
    }
   ],
   "source": [
    "speechtrainData = speech_preProcessData(SPEECH_TRAIN_CSV_FILE)\n",
    "speechtestData = speech_preProcessData(SPEECH_TEST_CSV_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8828ac80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>rmse</th>\n",
       "      <th>spectral_centroid</th>\n",
       "      <th>spectral_bandwidth</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zero_crossing_rate</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.324215</td>\n",
       "      <td>1158.867914</td>\n",
       "      <td>1396.735259</td>\n",
       "      <td>2292.729240</td>\n",
       "      <td>0.049880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.448211</td>\n",
       "      <td>2315.191869</td>\n",
       "      <td>2825.016168</td>\n",
       "      <td>5660.115774</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029656</td>\n",
       "      <td>0.462529</td>\n",
       "      <td>2252.689010</td>\n",
       "      <td>2801.919295</td>\n",
       "      <td>5501.109248</td>\n",
       "      <td>0.072039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015112</td>\n",
       "      <td>0.294097</td>\n",
       "      <td>1264.958471</td>\n",
       "      <td>1501.696181</td>\n",
       "      <td>2399.696045</td>\n",
       "      <td>0.056331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039543</td>\n",
       "      <td>0.364756</td>\n",
       "      <td>1195.501657</td>\n",
       "      <td>1441.521266</td>\n",
       "      <td>2293.134491</td>\n",
       "      <td>0.052418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.035723</td>\n",
       "      <td>0.530913</td>\n",
       "      <td>2264.746003</td>\n",
       "      <td>2785.203359</td>\n",
       "      <td>5571.524048</td>\n",
       "      <td>0.075823</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.346504</td>\n",
       "      <td>1321.168317</td>\n",
       "      <td>1710.770952</td>\n",
       "      <td>2618.676758</td>\n",
       "      <td>0.052479</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.023293</td>\n",
       "      <td>0.420064</td>\n",
       "      <td>1385.335041</td>\n",
       "      <td>1489.298766</td>\n",
       "      <td>2711.007366</td>\n",
       "      <td>0.077860</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.032848</td>\n",
       "      <td>0.444131</td>\n",
       "      <td>1172.923283</td>\n",
       "      <td>1470.429012</td>\n",
       "      <td>2282.157629</td>\n",
       "      <td>0.049333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.027095</td>\n",
       "      <td>0.410524</td>\n",
       "      <td>1305.024186</td>\n",
       "      <td>1461.966465</td>\n",
       "      <td>2485.712747</td>\n",
       "      <td>0.064535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chroma_stft      rmse  spectral_centroid  spectral_bandwidth  \\\n",
       "0       0.045838  0.324215        1158.867914         1396.735259   \n",
       "1       0.025397  0.448211        2315.191869         2825.016168   \n",
       "2       0.029656  0.462529        2252.689010         2801.919295   \n",
       "3       0.015112  0.294097        1264.958471         1501.696181   \n",
       "4       0.039543  0.364756        1195.501657         1441.521266   \n",
       "..           ...       ...                ...                 ...   \n",
       "137     0.035723  0.530913        2264.746003         2785.203359   \n",
       "138     0.009834  0.346504        1321.168317         1710.770952   \n",
       "139     0.023293  0.420064        1385.335041         1489.298766   \n",
       "140     0.032848  0.444131        1172.923283         1470.429012   \n",
       "141     0.027095  0.410524        1305.024186         1461.966465   \n",
       "\n",
       "         rolloff  zero_crossing_rate  number  \n",
       "0    2292.729240            0.049880       0  \n",
       "1    5660.115774            0.088334       1  \n",
       "2    5501.109248            0.072039       1  \n",
       "3    2399.696045            0.056331       1  \n",
       "4    2293.134491            0.052418       0  \n",
       "..           ...                 ...     ...  \n",
       "137  5571.524048            0.075823       1  \n",
       "138  2618.676758            0.052479       1  \n",
       "139  2711.007366            0.077860       1  \n",
       "140  2282.157629            0.049333       0  \n",
       "141  2485.712747            0.064535       1  \n",
       "\n",
       "[142 rows x 7 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speechtrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "686e1ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y from training data: (142,)\n",
      "Y from test data: (18,)\n"
     ]
    }
   ],
   "source": [
    "X_train_speech = np.array(speechtrainData.iloc[:, :-1], dtype = float)\n",
    "y_train_speech = speechtrainData.iloc[:, -1]\n",
    "X_test_speech = np.array(speechtestData.iloc[:, :-1], dtype = float)\n",
    "y_test_speech = speechtestData.iloc[:, -1]\n",
    "\n",
    "print(\"Y from training data:\", y_train_speech.shape)\n",
    "print(\"Y from test data:\", y_test_speech.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "734e3c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X from training data (142, 6)\n",
      "X from test data (18, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_train_speech = scaler.fit_transform( X_train_speech )\n",
    "X_test_speech = scaler.transform( X_test_speech )\n",
    "print(\"X from training data\", X_train_speech.shape)\n",
    "print(\"X from test data\", X_test_speech.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "52828924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtr_speech_classifier = DecisionTreeClassifier()\n",
    "Dtr_speech_classifier.fit(X_train_speech, y_train_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "08694731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Svm_speech_classifier = SVC()  \n",
    "Svm_speech_classifier.fit(X_train_speech, y_train_speech)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0c96f9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dtr_speech_classifier_prediciton = Dtr_speech_classifier.predict(X_test_speech)\n",
    "Dtr_speech_classifier_prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "c3481e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Svm_speech_classifier_pred = Svm_speech_classifier.predict(X_test_speech)\n",
    "Svm_speech_classifier_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "2f412a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_speech_classifier_SVM: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_speech_classifier_SVM:\",metrics.accuracy_score(y_test_speech, Svm_speech_classifier_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "4267fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_speech_classifier_Dtr: 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy_speech_classifier_Dtr:\",metrics.accuracy_score(y_test_speech, Dtr_speech_classifier_prediciton))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "11304873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_input(input_audio):\n",
    "    extracted_features = []\n",
    "    y, sr = librosa.load(input_audio, mono=True)\n",
    "    y, index = librosa.effects.trim(y)\n",
    "    rmse = librosa.feature.rms(y=y)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "\n",
    "#     mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc = 60)\n",
    "    extracted_features.extend([np.mean(rmse), np.mean(chroma_stft), np.mean(spec_cent),np.mean(spec_bw), np.mean(rolloff), np.mean(zcr)])\n",
    "#     for e in mfcc:\n",
    "#         extracted_features.append(np.mean(e))\n",
    "    return np.array(extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "0c92c97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio = 'Audio_Data/open_test1.wav'\n",
    "audio_features = extract_features_from_input(input_audio)\n",
    "audio_features = audio_features.reshape(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "adc5e9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice of Open\n"
     ]
    }
   ],
   "source": [
    "prediction = Dtr_speech_classifier.predict(np.array(audio_features))\n",
    "speakers_list = [(0, 'Open'), (1, 'other')]\n",
    "for iterator, speech in enumerate(speakers_list):\n",
    "    if prediction[0] == speech[0]:\n",
    "        print(\"voice of \" + speech[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "b1865ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "import pickle\n",
    "filename = 'speech_classifier_final.sav'\n",
    "pickle.dump(Dtr_speech_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "1997259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice of Open\n"
     ]
    }
   ],
   "source": [
    "prediction = Svm_speech_classifier.predict(np.array(audio_features))\n",
    "speakers_list = [(0, 'Open'), (1, 'other')]\n",
    "for iterator, speech in enumerate(speakers_list):\n",
    "    if prediction[0] == speech[0]:\n",
    "        print(\"voice of \" + speech[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "d2407873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "074f1e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "y_pred=clf.predict(X_test_speech)\n",
    "\n",
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_speech, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "882102a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voice of other\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.predict(np.array(audio_features))\n",
    "speakers_list = [(0, 'Open'), (1, 'other')]\n",
    "for iterator, speech in enumerate(speakers_list):\n",
    "    if prediction[0] == speech[0]:\n",
    "        print(\"voice of \" + speech[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d687cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Dtr_speech_classifier.sav'\n",
    "pickle.dump(Dtr_speech_classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4d9a2",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
